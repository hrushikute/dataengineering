{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5373098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libs\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "\n",
    "username=getpass.getuser()\n",
    "spark=SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port','0'). \\\n",
    "    config(\"spark.suffle.useOldFetchProtocol\",'true'). \\\n",
    "    config(\"spark.dql.warehouse.dir\",f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d9be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_raw_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",True) \\\n",
    ".option(\"inferSchema\", True) \\\n",
    ".load(\"/user/itv014478/lendingclubproject/raw/loan_repayment_data_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3355da78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loan_id</th><th>total_rec_int</th><th>total_rec_late_fee</th><th>total_pymnt</th><th>last_pymnt_amnt</th><th>last_pymnt_d</th><th>next_pymnt_d</th></tr>\n",
       "<tr><td>68407277</td><td>821.72</td><td>0.0</td><td>4421.723916800001</td><td>122.67</td><td>Jan-2019</td><td>null</td></tr>\n",
       "<tr><td>68355089</td><td>979.66</td><td>0.0</td><td>25679.66</td><td>926.35</td><td>Jun-2016</td><td>null</td></tr>\n",
       "<tr><td>68341763</td><td>2705.92</td><td>0.0</td><td>22705.924293878397</td><td>15813.3</td><td>Jun-2017</td><td>null</td></tr>\n",
       "<tr><td>66310712</td><td>12361.66</td><td>0.0</td><td>31464.01</td><td>829.9</td><td>Feb-2019</td><td>Apr-2019</td></tr>\n",
       "<tr><td>68476807</td><td>1340.5</td><td>0.0</td><td>11740.5</td><td>10128.96</td><td>Jul-2016</td><td>null</td></tr>\n",
       "<tr><td>68426831</td><td>1758.95</td><td>0.0</td><td>13708.9485297572</td><td>7653.56</td><td>May-2017</td><td>null</td></tr>\n",
       "<tr><td>68476668</td><td>1393.8</td><td>0.0</td><td>21393.800000011</td><td>15681.05</td><td>Nov-2016</td><td>null</td></tr>\n",
       "<tr><td>67275481</td><td>1538.51</td><td>0.0</td><td>21538.508976797</td><td>14618.23</td><td>Jan-2017</td><td>null</td></tr>\n",
       "<tr><td>68466926</td><td>998.97</td><td>0.0</td><td>10998.9715749644</td><td>1814.48</td><td>Aug-2018</td><td>null</td></tr>\n",
       "<tr><td>68616873</td><td>939.58</td><td>0.0</td><td>8939.5805031401</td><td>4996.24</td><td>Apr-2017</td><td>null</td></tr>\n",
       "<tr><td>68356421</td><td>6788.21</td><td>0.0</td><td>19275.33</td><td>508.3</td><td>Feb-2019</td><td>Apr-2019</td></tr>\n",
       "<tr><td>68426545</td><td>4848.74</td><td>0.0</td><td>13768.04</td><td>363.07</td><td>Feb-2019</td><td>Apr-2019</td></tr>\n",
       "<tr><td>68338832</td><td>175.16</td><td>0.0</td><td>1575.160697674</td><td>965.36</td><td>Mar-2017</td><td>null</td></tr>\n",
       "<tr><td>66624733</td><td>4351.98</td><td>0.0</td><td>9452.74</td><td>471.7</td><td>May-2017</td><td>null</td></tr>\n",
       "<tr><td>68466961</td><td>1939.02</td><td>0.0</td><td>29939.017729337003</td><td>17093.51</td><td>May-2017</td><td>null</td></tr>\n",
       "<tr><td>68354783</td><td>1036.1</td><td>0.0</td><td>10636.098427692801</td><td>3480.17</td><td>Feb-2018</td><td>null</td></tr>\n",
       "<tr><td>68466916</td><td>1224.23</td><td>0.0</td><td>26224.23</td><td>20807.39</td><td>Sep-2016</td><td>null</td></tr>\n",
       "<tr><td>68577849</td><td>387.22</td><td>0.0</td><td>18387.22</td><td>18004.9</td><td>Mar-2016</td><td>null</td></tr>\n",
       "<tr><td>68506798</td><td>4480.34</td><td>0.0</td><td>17900.14</td><td>471.77</td><td>Feb-2019</td><td>Apr-2019</td></tr>\n",
       "<tr><td>68495092</td><td>540.49</td><td>0.0</td><td>9190.49</td><td>8251.42</td><td>May-2016</td><td>null</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+-------------+------------------+------------------+---------------+------------+------------+\n",
       "| loan_id|total_rec_int|total_rec_late_fee|       total_pymnt|last_pymnt_amnt|last_pymnt_d|next_pymnt_d|\n",
       "+--------+-------------+------------------+------------------+---------------+------------+------------+\n",
       "|68407277|       821.72|               0.0| 4421.723916800001|         122.67|    Jan-2019|        null|\n",
       "|68355089|       979.66|               0.0|          25679.66|         926.35|    Jun-2016|        null|\n",
       "|68341763|      2705.92|               0.0|22705.924293878397|        15813.3|    Jun-2017|        null|\n",
       "|66310712|     12361.66|               0.0|          31464.01|          829.9|    Feb-2019|    Apr-2019|\n",
       "|68476807|       1340.5|               0.0|           11740.5|       10128.96|    Jul-2016|        null|\n",
       "|68426831|      1758.95|               0.0|  13708.9485297572|        7653.56|    May-2017|        null|\n",
       "|68476668|       1393.8|               0.0|   21393.800000011|       15681.05|    Nov-2016|        null|\n",
       "|67275481|      1538.51|               0.0|   21538.508976797|       14618.23|    Jan-2017|        null|\n",
       "|68466926|       998.97|               0.0|  10998.9715749644|        1814.48|    Aug-2018|        null|\n",
       "|68616873|       939.58|               0.0|   8939.5805031401|        4996.24|    Apr-2017|        null|\n",
       "|68356421|      6788.21|               0.0|          19275.33|          508.3|    Feb-2019|    Apr-2019|\n",
       "|68426545|      4848.74|               0.0|          13768.04|         363.07|    Feb-2019|    Apr-2019|\n",
       "|68338832|       175.16|               0.0|    1575.160697674|         965.36|    Mar-2017|        null|\n",
       "|66624733|      4351.98|               0.0|           9452.74|          471.7|    May-2017|        null|\n",
       "|68466961|      1939.02|               0.0|29939.017729337003|       17093.51|    May-2017|        null|\n",
       "|68354783|       1036.1|               0.0|10636.098427692801|        3480.17|    Feb-2018|        null|\n",
       "|68466916|      1224.23|               0.0|          26224.23|       20807.39|    Sep-2016|        null|\n",
       "|68577849|       387.22|               0.0|          18387.22|        18004.9|    Mar-2016|        null|\n",
       "|68506798|      4480.34|               0.0|          17900.14|         471.77|    Feb-2019|    Apr-2019|\n",
       "|68495092|       540.49|               0.0|           9190.49|        8251.42|    May-2016|        null|\n",
       "+--------+-------------+------------------+------------------+---------------+------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_repay_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a17d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- total_rec_int: double (nullable = true)\n",
      " |-- total_rec_late_fee: double (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- last_pymnt_amnt: string (nullable = true)\n",
      " |-- last_pymnt_d: string (nullable = true)\n",
      " |-- next_pymnt_d: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_repay_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a990f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_schema = 'loan_id string, total_principal_received float, total_interest_received float, total_late_fee_received float, total_payment_received float, last_payment_amount float, last_payment_date string, next_payment_date string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cb0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_raw_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",True) \\\n",
    ".schema(loans_repay_schema) \\\n",
    ".load(\"/user/itv014478/lendingclubproject/raw/loan_repayment_data_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c0b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- total_principal_received: float (nullable = true)\n",
      " |-- total_interest_received: float (nullable = true)\n",
      " |-- total_late_fee_received: float (nullable = true)\n",
      " |-- total_payment_received: float (nullable = true)\n",
      " |-- last_payment_amount: float (nullable = true)\n",
      " |-- last_payment_date: string (nullable = true)\n",
      " |-- next_payment_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_repay_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4782de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86729760",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_df_ingestd = loans_repay_raw_df.withColumn(\"ingest_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d51534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loan_id</th><th>total_principal_received</th><th>total_interest_received</th><th>total_late_fee_received</th><th>total_payment_received</th><th>last_payment_amount</th><th>last_payment_date</th><th>next_payment_date</th><th>ingest_date</th></tr>\n",
       "<tr><td>68407277</td><td>821.72</td><td>0.0</td><td>4421.724</td><td>122.67</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68355089</td><td>979.66</td><td>0.0</td><td>25679.66</td><td>926.35</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68341763</td><td>2705.92</td><td>0.0</td><td>22705.924</td><td>15813.3</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>66310712</td><td>12361.66</td><td>0.0</td><td>31464.01</td><td>829.9</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68476807</td><td>1340.5</td><td>0.0</td><td>11740.5</td><td>10128.96</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68426831</td><td>1758.95</td><td>0.0</td><td>13708.948</td><td>7653.56</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68476668</td><td>1393.8</td><td>0.0</td><td>21393.8</td><td>15681.05</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>67275481</td><td>1538.51</td><td>0.0</td><td>21538.51</td><td>14618.23</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68466926</td><td>998.97</td><td>0.0</td><td>10998.972</td><td>1814.48</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68616873</td><td>939.58</td><td>0.0</td><td>8939.58</td><td>4996.24</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68356421</td><td>6788.21</td><td>0.0</td><td>19275.33</td><td>508.3</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68426545</td><td>4848.74</td><td>0.0</td><td>13768.04</td><td>363.07</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68338832</td><td>175.16</td><td>0.0</td><td>1575.1606</td><td>965.36</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>66624733</td><td>4351.98</td><td>0.0</td><td>9452.74</td><td>471.7</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68466961</td><td>1939.02</td><td>0.0</td><td>29939.018</td><td>17093.51</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68354783</td><td>1036.1</td><td>0.0</td><td>10636.099</td><td>3480.17</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68466916</td><td>1224.23</td><td>0.0</td><td>26224.23</td><td>20807.39</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68577849</td><td>387.22</td><td>0.0</td><td>18387.22</td><td>18004.9</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68506798</td><td>4480.34</td><td>0.0</td><td>17900.14</td><td>471.77</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "<tr><td>68495092</td><td>540.49</td><td>0.0</td><td>9190.49</td><td>8251.42</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:34:...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "| loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "|68407277|                  821.72|                    0.0|               4421.724|                122.67|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68355089|                  979.66|                    0.0|               25679.66|                926.35|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68341763|                 2705.92|                    0.0|              22705.924|               15813.3|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|66310712|                12361.66|                    0.0|               31464.01|                 829.9|               null|         Apr-2019|             null|2024-11-19 03:34:...|\n",
       "|68476807|                  1340.5|                    0.0|                11740.5|              10128.96|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68426831|                 1758.95|                    0.0|              13708.948|               7653.56|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68476668|                  1393.8|                    0.0|                21393.8|              15681.05|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|67275481|                 1538.51|                    0.0|               21538.51|              14618.23|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68466926|                  998.97|                    0.0|              10998.972|               1814.48|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68616873|                  939.58|                    0.0|                8939.58|               4996.24|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68356421|                 6788.21|                    0.0|               19275.33|                 508.3|               null|         Apr-2019|             null|2024-11-19 03:34:...|\n",
       "|68426545|                 4848.74|                    0.0|               13768.04|                363.07|               null|         Apr-2019|             null|2024-11-19 03:34:...|\n",
       "|68338832|                  175.16|                    0.0|              1575.1606|                965.36|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|66624733|                 4351.98|                    0.0|                9452.74|                 471.7|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68466961|                 1939.02|                    0.0|              29939.018|              17093.51|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68354783|                  1036.1|                    0.0|              10636.099|               3480.17|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68466916|                 1224.23|                    0.0|               26224.23|              20807.39|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68577849|                  387.22|                    0.0|               18387.22|               18004.9|               null|             null|             null|2024-11-19 03:34:...|\n",
       "|68506798|                 4480.34|                    0.0|               17900.14|                471.77|               null|         Apr-2019|             null|2024-11-19 03:34:...|\n",
       "|68495092|                  540.49|                    0.0|                9190.49|               8251.42|               null|             null|             null|2024-11-19 03:34:...|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_repay_df_ingestd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b13eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- total_principal_received: float (nullable = true)\n",
      " |-- total_interest_received: float (nullable = true)\n",
      " |-- total_late_fee_received: float (nullable = true)\n",
      " |-- total_payment_received: float (nullable = true)\n",
      " |-- last_payment_amount: float (nullable = true)\n",
      " |-- last_payment_date: string (nullable = true)\n",
      " |-- next_payment_date: string (nullable = true)\n",
      " |-- ingest_date: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loans_repay_df_ingestd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52502d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462494"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_repay_df_ingestd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a2b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_df_ingestd.createOrReplaceTempView(\"loan_repayments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61041770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(1)</th></tr>\n",
       "<tr><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|       2|\n",
       "+--------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from loan_repayments where total_principal_received is null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bcedb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = [\"total_principal_received\", \"total_interest_received\", \"total_late_fee_received\", \"total_payment_received\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff96fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_filtered_df = loans_repay_df_ingestd.na.drop(subset=columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6fcbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462491"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_repay_filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8ec648",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_filtered_df.createOrReplaceTempView(\"loan_repayments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25f406c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(1)</th></tr>\n",
       "<tr><td>396</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "|     396|\n",
       "+--------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from loan_repayments where total_payment_received = 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a662d67",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o161.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.lang.IllegalArgumentException: Unknown message type: 9 \tat org.apache.spark.network.shuffle.protocol.BlockTransferMessage$Decoder.fromByteBuffer(BlockTransferMessage.java:71) \tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.receive(ExternalShuffleBlockHandler.java:80) \tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:180) \tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat org.spark_project.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat org.spark_project.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat org.spark_project.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat org.spark_project.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \tat java.lang.Thread.run(Thread.java:748)  \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) \tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) \tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) \tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithoutKey_0$(Unknown Source) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source) \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755) \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345) \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898) \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898) \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337) \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) \tat org.apache.spark.scheduler.Task.run(Task.scala:131) \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) \tat java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.lang.IllegalArgumentException: Unknown message type: 9 \tat org.apache.spark.network.shuffle.protocol.BlockTransferMessage$Decoder.fromByteBuffer(BlockTransferMessage.java:71) \tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.receive(ExternalShuffleBlockHandler.java:80) \tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:180) \tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat org.spark_project.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat org.spark_project.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat org.spark_project.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat org.spark_project.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \tat java.lang.Thread.run(Thread.java:748)  \tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:208) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) \tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \t... 1 more \n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/beakerx/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/beakerx/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/beakerx/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m             return self._jdf.showString(\n\u001b[1;32m    492\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplEagerEvalMaxNumRows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 self.sql_ctx._conf.replEagerEvalTruncate(), vertical)\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"DataFrame[%s]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o161.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 21 (showString at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.lang.IllegalArgumentException: Unknown message type: 9 \tat org.apache.spark.network.shuffle.protocol.BlockTransferMessage$Decoder.fromByteBuffer(BlockTransferMessage.java:71) \tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.receive(ExternalShuffleBlockHandler.java:80) \tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:180) \tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat org.spark_project.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat org.spark_project.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat org.spark_project.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat org.spark_project.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \tat java.lang.Thread.run(Thread.java:748)  \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:770) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:685) \tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:70) \tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) \tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484) \tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490) \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) \tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) \tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) \tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithoutKey_0$(Unknown Source) \tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source) \tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) \tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755) \tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345) \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898) \tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898) \tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) \tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373) \tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337) \tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) \tat org.apache.spark.scheduler.Task.run(Task.scala:131) \tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497) \tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439) \tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500) \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) \tat java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.lang.IllegalArgumentException: Unknown message type: 9 \tat org.apache.spark.network.shuffle.protocol.BlockTransferMessage$Decoder.fromByteBuffer(BlockTransferMessage.java:71) \tat org.apache.spark.network.shuffle.ExternalShuffleBlockHandler.receive(ExternalShuffleBlockHandler.java:80) \tat org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:180) \tat org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:103) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:118) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:85) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat org.spark_project.io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat org.spark_project.io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat org.spark_project.io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat org.spark_project.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat org.spark_project.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat org.spark_project.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat org.spark_project.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \tat java.lang.Thread.run(Thread.java:748)  \tat org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:208) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142) \tat org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53) \tat io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:102) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) \tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) \tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) \tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) \tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163) \tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714) \tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650) \tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576) \tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493) \tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) \tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) \t... 1 more \n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1768)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2442)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>count(1)</th></tr>\n",
       "<tr><td>37</td></tr>\n",
       "</table>\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from loan_repayments where total_payment_received = 0.0 and total_principal_received != 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b9e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loan_id</th><th>total_principal_received</th><th>total_interest_received</th><th>total_late_fee_received</th><th>total_payment_received</th><th>last_payment_amount</th><th>last_payment_date</th><th>next_payment_date</th><th>ingest_date</th></tr>\n",
       "<tr><td>68373395</td><td>841.01</td><td>0.0</td><td>10841.013</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>67999698</td><td>2735.37</td><td>0.0</td><td>19535.371</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>65945334</td><td>1206.41</td><td>0.0</td><td>12206.413</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>66064197</td><td>6527.91</td><td>0.0</td><td>29527.914</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>65874763</td><td>5441.86</td><td>0.0</td><td>25441.861</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>65601746</td><td>2376.69</td><td>0.0</td><td>14451.691</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>63444672</td><td>5041.51</td><td>0.0</td><td>25041.512</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61504248</td><td>1334.93</td><td>0.0</td><td>14834.932</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61473016</td><td>1137.38</td><td>0.0</td><td>17137.383</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61361777</td><td>1093.83</td><td>0.0</td><td>11893.827</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61479533</td><td>344.46</td><td>0.0</td><td>5944.461</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61429202</td><td>2184.23</td><td>0.0</td><td>18184.229</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>61479017</td><td>1032.68</td><td>0.0</td><td>11032.68</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>59638665</td><td>4167.82</td><td>0.0</td><td>19167.822</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>59511659</td><td>13421.58</td><td>0.0</td><td>41421.586</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>59601218</td><td>625.0</td><td>15.0</td><td>3640.0002</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>58983292</td><td>1157.05</td><td>0.0</td><td>6757.052</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>58502227</td><td>2439.83</td><td>0.0</td><td>17439.83</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>57703593</td><td>1688.84</td><td>0.0</td><td>8688.844</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "<tr><td>56934154</td><td>1504.18</td><td>0.0</td><td>19504.182</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:38:...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "| loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "|68373395|                  841.01|                    0.0|              10841.013|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|67999698|                 2735.37|                    0.0|              19535.371|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|65945334|                 1206.41|                    0.0|              12206.413|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|66064197|                 6527.91|                    0.0|              29527.914|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|65874763|                 5441.86|                    0.0|              25441.861|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|65601746|                 2376.69|                    0.0|              14451.691|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|63444672|                 5041.51|                    0.0|              25041.512|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61504248|                 1334.93|                    0.0|              14834.932|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61473016|                 1137.38|                    0.0|              17137.383|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61361777|                 1093.83|                    0.0|              11893.827|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61479533|                  344.46|                    0.0|               5944.461|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61429202|                 2184.23|                    0.0|              18184.229|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|61479017|                 1032.68|                    0.0|               11032.68|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|59638665|                 4167.82|                    0.0|              19167.822|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|59511659|                13421.58|                    0.0|              41421.586|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|59601218|                   625.0|                   15.0|              3640.0002|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|58983292|                 1157.05|                    0.0|               6757.052|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|58502227|                 2439.83|                    0.0|               17439.83|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|57703593|                 1688.84|                    0.0|               8688.844|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "|56934154|                 1504.18|                    0.0|              19504.182|                   0.0|               null|             null|             null|2024-11-19 03:38:...|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from loan_repayments where total_payment_received = 0.0 and total_principal_received != 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc44382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "loans_payments_fixed_df = loans_repay_filtered_df.withColumn(\n",
    "   \"total_payment_received\",\n",
    "    when(\n",
    "        (col(\"total_principal_received\") != 0.0) &\n",
    "        (col(\"total_payment_received\") == 0.0),\n",
    "        col(\"total_principal_received\") + col(\"total_interest_received\") + col(\"total_late_fee_received\")\n",
    "    ).otherwise(col(\"total_payment_received\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87801fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loan_id</th><th>total_principal_received</th><th>total_interest_received</th><th>total_late_fee_received</th><th>total_payment_received</th><th>last_payment_amount</th><th>last_payment_date</th><th>next_payment_date</th><th>ingest_date</th></tr>\n",
       "<tr><td>68407277</td><td>821.72</td><td>0.0</td><td>4421.724</td><td>122.67</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68355089</td><td>979.66</td><td>0.0</td><td>25679.66</td><td>926.35</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68341763</td><td>2705.92</td><td>0.0</td><td>22705.924</td><td>15813.3</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>66310712</td><td>12361.66</td><td>0.0</td><td>31464.01</td><td>829.9</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68476807</td><td>1340.5</td><td>0.0</td><td>11740.5</td><td>10128.96</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68426831</td><td>1758.95</td><td>0.0</td><td>13708.948</td><td>7653.56</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68476668</td><td>1393.8</td><td>0.0</td><td>21393.8</td><td>15681.05</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>67275481</td><td>1538.51</td><td>0.0</td><td>21538.51</td><td>14618.23</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68466926</td><td>998.97</td><td>0.0</td><td>10998.972</td><td>1814.48</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68616873</td><td>939.58</td><td>0.0</td><td>8939.58</td><td>4996.24</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68356421</td><td>6788.21</td><td>0.0</td><td>19275.33</td><td>508.3</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68426545</td><td>4848.74</td><td>0.0</td><td>13768.04</td><td>363.07</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68338832</td><td>175.16</td><td>0.0</td><td>1575.1606</td><td>965.36</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>66624733</td><td>4351.98</td><td>0.0</td><td>9452.74</td><td>471.7</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68466961</td><td>1939.02</td><td>0.0</td><td>29939.018</td><td>17093.51</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68354783</td><td>1036.1</td><td>0.0</td><td>10636.099</td><td>3480.17</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68466916</td><td>1224.23</td><td>0.0</td><td>26224.23</td><td>20807.39</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68577849</td><td>387.22</td><td>0.0</td><td>18387.22</td><td>18004.9</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68506798</td><td>4480.34</td><td>0.0</td><td>17900.14</td><td>471.77</td><td>null</td><td>Apr-2019</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "<tr><td>68495092</td><td>540.49</td><td>0.0</td><td>9190.49</td><td>8251.42</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:41:...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "| loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "|68407277|                  821.72|                    0.0|               4421.724|                122.67|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68355089|                  979.66|                    0.0|               25679.66|                926.35|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68341763|                 2705.92|                    0.0|              22705.924|               15813.3|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|66310712|                12361.66|                    0.0|               31464.01|                 829.9|               null|         Apr-2019|             null|2024-11-19 03:41:...|\n",
       "|68476807|                  1340.5|                    0.0|                11740.5|              10128.96|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68426831|                 1758.95|                    0.0|              13708.948|               7653.56|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68476668|                  1393.8|                    0.0|                21393.8|              15681.05|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|67275481|                 1538.51|                    0.0|               21538.51|              14618.23|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68466926|                  998.97|                    0.0|              10998.972|               1814.48|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68616873|                  939.58|                    0.0|                8939.58|               4996.24|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68356421|                 6788.21|                    0.0|               19275.33|                 508.3|               null|         Apr-2019|             null|2024-11-19 03:41:...|\n",
       "|68426545|                 4848.74|                    0.0|               13768.04|                363.07|               null|         Apr-2019|             null|2024-11-19 03:41:...|\n",
       "|68338832|                  175.16|                    0.0|              1575.1606|                965.36|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|66624733|                 4351.98|                    0.0|                9452.74|                 471.7|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68466961|                 1939.02|                    0.0|              29939.018|              17093.51|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68354783|                  1036.1|                    0.0|              10636.099|               3480.17|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68466916|                 1224.23|                    0.0|               26224.23|              20807.39|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68577849|                  387.22|                    0.0|               18387.22|               18004.9|               null|             null|             null|2024-11-19 03:41:...|\n",
       "|68506798|                 4480.34|                    0.0|               17900.14|                471.77|               null|         Apr-2019|             null|2024-11-19 03:41:...|\n",
       "|68495092|                  540.49|                    0.0|                9190.49|               8251.42|               null|             null|             null|2024-11-19 03:41:...|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae41f7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>loan_id</th><th>total_principal_received</th><th>total_interest_received</th><th>total_late_fee_received</th><th>total_payment_received</th><th>last_payment_amount</th><th>last_payment_date</th><th>next_payment_date</th><th>ingest_date</th></tr>\n",
       "<tr><td>59601218</td><td>625.0</td><td>15.0</td><td>3640.0002</td><td>4280.0</td><td>null</td><td>null</td><td>null</td><td>2024-11-19 03:43:...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "| loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
       "|59601218|                   625.0|                   15.0|              3640.0002|                4280.0|               null|             null|             null|2024-11-19 03:43:...|\n",
       "+--------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed_df.filter(\"loan_id == '59601218'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2334da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_payments_fixed2_df = loans_payments_fixed_df.filter(\"total_payment_received != 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e624483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382863"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed2_df.filter(\"last_payment_date is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fc15cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_payments_fixed2_df.write \\\n",
    ".format(\"parquet\") \\\n",
    ".mode(\"overwrite\") \\\n",
    ".option(\"path\", \"/user/itv014478/lendingclubproject/cleaned/loans_repayments_parquet\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d30d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
